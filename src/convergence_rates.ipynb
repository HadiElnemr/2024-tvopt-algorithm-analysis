{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "import control as ctrl\n",
    "import scipy.linalg as linalg\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "from fct.solver import PolynomialLyapunovMatrix\n",
    "from fct.algorithms import GradientDescent, Nesterov, TMM\n",
    "from fct.consistent_polytope import ConsistentPolytope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def lti_stack(sys1, sys2):\n",
    "    A1, B1, C1, D1 = ctrl.ssdata(sys1)\n",
    "    A2, B2, C2, D2 = ctrl.ssdata(sys2)\n",
    "\n",
    "    if B1.shape[1] != B2.shape[1]:\n",
    "        raise ValueError('Error in system stacking: number of inputs must be the same for both subsystems!')\n",
    "\n",
    "    A = linalg.block_diag(A1, A2)\n",
    "    B = np.vstack((B1, B2))\n",
    "    C = linalg.block_diag(C1, C2)\n",
    "    D = np.vstack((D1, D2))\n",
    "\n",
    "    return ctrl.ss(A, B, C, D, dt=1)\n",
    "\n",
    "\n",
    "def consistent_polytope_nd(params, delta_params_min, delta_params_max, step_size=0.1):\n",
    "    \"\"\"\n",
    "    Generates grid points such that p_min <= p + delta_p <= p_max\n",
    "    and delta_p_min <= delta_p <= delta_p_max for each parameter vector.\n",
    "\n",
    "    Parameters:\n",
    "        params (numpy.ndarray): A 2D array where each row represents a parameter vector.\n",
    "        delta_params_min (numpy.ndarray): Minimum allowable deltas for each parameter.\n",
    "        delta_params_max (numpy.ndarray): Maximum allowable deltas for each parameter.\n",
    "        step_size (float): Step size for generating grid points in the delta ranges.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, each containing (p_k, delta_p) where p_k is the parameter vector\n",
    "              and delta_p is the corresponding delta vector satisfying the constraints.\n",
    "    \"\"\"\n",
    "    # Handle 1D input by converting it to 2D for uniform processing\n",
    "    if params.ndim == 1:\n",
    "        params = params[None, :]  # Convert to shape (1, n)\n",
    "        delta_params_min = np.array([delta_params_min])\n",
    "        delta_params_max = np.array([delta_params_max])\n",
    "\n",
    "    # Calculate global min and max for params directly using numpy\n",
    "    p_min = np.min(params, axis=1)\n",
    "    p_max = np.max(params, axis=1)\n",
    "\n",
    "    # Initialize the grid points for (p, delta_p)\n",
    "    grid_points = []\n",
    "\n",
    "    # Loop through each parameter vector\n",
    "    for k in range(params.shape[1]):\n",
    "        p_k = params[:, k]\n",
    "\n",
    "        # Determine feasible ranges for deltas for each dimension\n",
    "        delta_min_k = np.maximum(delta_params_min, np.maximum(p_min - p_k, -delta_params_max))\n",
    "        delta_max_k = np.minimum(delta_params_max, np.minimum(p_max - p_k, delta_params_max))\n",
    "\n",
    "        # Generate grid points for all dimensions\n",
    "        delta_ranges = []\n",
    "        for d in range(params.shape[0]):\n",
    "            delta_min = delta_min_k[d]\n",
    "            delta_max = delta_max_k[d]\n",
    "            num_dp_points = int((delta_max - delta_min) / step_size) + 1\n",
    "            range_points = [\n",
    "                min(delta_min + j * step_size, delta_max)  # Ensure boundary inclusion\n",
    "                for j in range(num_dp_points)\n",
    "            ]\n",
    "            if range_points[-1] < delta_max:\n",
    "                range_points.append(delta_max)\n",
    "\n",
    "            delta_ranges.append(np.array(range_points))\n",
    "\n",
    "        # Create a meshgrid of delta ranges and iterate through combinations\n",
    "        delta_mesh = np.meshgrid(*delta_ranges, indexing=\"ij\")\n",
    "        delta_combinations = np.stack([delta.ravel() for delta in delta_mesh], axis=-1)\n",
    "\n",
    "        for delta_p in delta_combinations:\n",
    "            delta_p = np.clip(delta_p, delta_params_min, delta_params_max)\n",
    "            grid_points.append((p_k, delta_p))\n",
    "\n",
    "    return grid_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(algorithm, delta_model, rho_max, consistent_polytope, eps=1e-6):\n",
    "\n",
    "    soll = (np.nan, np.nan, np.nan, np.nan, np.nan)\n",
    "\n",
    "    ### get dimensions ###\n",
    "    n_xi = algorithm.internal_state_dim\n",
    "    n_x, n_g  = algorithm.nx, algorithm.nx\n",
    "    if delta_model:\n",
    "        n_delt = n_xi\n",
    "        n_zeta = 1\n",
    "    else:\n",
    "        n_delt = 0\n",
    "        n_zeta = 0\n",
    "    n_eta = n_xi + n_zeta\n",
    "\n",
    "    I_n_eta = np.eye(n_eta)\n",
    "\n",
    "    ### start bisection ###\n",
    "    rho_min = 0\n",
    "    rho_tol = 1e-3\n",
    "\n",
    "    while (rho_max-rho_min > rho_tol):\n",
    "\n",
    "        rho = (rho_min + rho_max)/2\n",
    "\n",
    "        ### SDP variables ###\n",
    "        LMI_system = list()\n",
    "        \n",
    "        lyap = PolynomialLyapunovMatrix(param_dim=1, poly_degree=2, n_eta=n_eta)\n",
    "\n",
    "        lambd1 = cvx.Variable(1, nonneg=True)\n",
    "        gamm   = cvx.Variable(1, nonneg=True) if delta_model else 0\n",
    "        lambd2 = cvx.Variable(1, nonneg=True) if delta_model else 0 #TODO: if should depend on IQC, not on delta_model\n",
    "        t      = cvx.Variable(1, nonneg=True)\n",
    "\n",
    "        t_I = cvx.multiply(t, I_n_eta)\n",
    "\n",
    "        ### grid over parameter space ###\n",
    "        for p_k, delta_p in consistent_polytope:\n",
    "\n",
    "            p_kp1 = p_k + delta_p\n",
    "\n",
    "            P_k   = lyap.P(p_k)\n",
    "            P_kp1 = lyap.P(p_kp1)\n",
    "\n",
    "            ### algorithm ###\n",
    "            algorithm.update_algorithm(m=1, L=p_k[0])\n",
    "            G = algorithm.get_state_space(delta_model=delta_model)\n",
    "\n",
    "            ### IQCs ###\n",
    "            A_psi = 0\n",
    "            B_psi = np.asarray([[-p_k[0], 1]])\n",
    "            C_psi = np.asarray([[rho**2], [0]])\n",
    "            D_psi = np.asarray([[p_k[0], -1], [-1, 1]])\n",
    "\n",
    "            M_sector = np.asarray([[0, 1], [1, 0]])\n",
    "\n",
    "            if delta_model:\n",
    "                D_psi_sec = np.block([D_psi, np.zeros((2,n_delt))])\n",
    "\n",
    "                B_psi = np.block([B_psi, -G.C])\n",
    "                D_psi = np.block([D_psi, np.zeros((D_psi.shape[0],G.C.shape[1]))])\n",
    "                M_offby1 = np.asarray([[0, 1], [1, 0]])\n",
    "            else:\n",
    "                D_psi_sec = D_psi\n",
    "                M_offby1 = np.asarray([[0, 1], [1, 0]])\n",
    "\n",
    "            Psi_sector = ctrl.ss([], [], [], D_psi_sec, dt=1)\n",
    "            Psi_offby1 = ctrl.ss(A_psi, B_psi, C_psi, D_psi, dt=1)\n",
    "\n",
    "            ### extended plant ###\n",
    "            Psi = lti_stack(Psi_sector, Psi_offby1) if delta_model else Psi_sector\n",
    "            G_I = lti_stack(G, np.eye(n_g+n_delt))\n",
    "            G_hat = ctrl.series(G_I, Psi)\n",
    "            A, B, C, D = ctrl.ssdata(G_hat)\n",
    "\n",
    "            nz1 = M_sector.shape[0]\n",
    "            nz2 = M_offby1.shape[0]\n",
    "            nz = nz1 + nz2 if delta_model else nz1 #TODO: should depend on IQC instead of delta_model\n",
    "\n",
    "            if delta_model:\n",
    "                LMI_inner = cvx.bmat([\n",
    "                    [-rho**2 * P_k, np.zeros((n_eta, n_eta)), np.zeros((n_eta, nz)), np.zeros((n_eta, n_delt))],\n",
    "                    [np.zeros((n_eta, n_eta)), P_kp1, np.zeros((n_eta, nz)), np.zeros((n_eta, n_delt))],\n",
    "                    [np.zeros((nz, n_eta)), np.zeros((nz, n_eta)), cvx.bmat([[lambd1 * M_sector, np.zeros((nz1, nz2))], \n",
    "                                                                             [np.zeros((nz2, nz1)), lambd2 * M_offby1]]), np.zeros((nz, n_delt))], \n",
    "                    [np.zeros((n_delt, n_eta)), np.zeros((n_delt, n_eta)), np.zeros((n_delt, nz)), -cvx.multiply(gamm, np.eye(n_delt))]\n",
    "                ])\n",
    "\n",
    "                LMI_outer = cvx.bmat([\n",
    "                    [I_n_eta, np.zeros((n_eta, n_g + n_delt))],\n",
    "                    [cvx.bmat([[A, B]])],\n",
    "                    [cvx.bmat([[C, D]])],\n",
    "                    [np.zeros((n_delt, n_eta + n_g)), np.eye(n_delt)]\n",
    "                ])\n",
    "\n",
    "            else:\n",
    "                LMI_inner = cvx.bmat([\n",
    "                    [-rho**2 * P_k, np.zeros((n_eta, n_eta)), np.zeros((n_eta, nz))],\n",
    "                    [np.zeros((n_eta, n_eta)), P_kp1, np.zeros((n_eta, nz))],\n",
    "                    [np.zeros((nz, n_eta)), np.zeros((nz, n_eta)), cvx.multiply(M_sector, lambd1)]\n",
    "                ])\n",
    "\n",
    "                LMI_outer = cvx.bmat([\n",
    "                    [I_n_eta, np.zeros((n_eta, n_g))],\n",
    "                    [cvx.bmat([[A, B]])],\n",
    "                    [cvx.bmat([[C, D]])]\n",
    "                ])\n",
    "\n",
    "\n",
    "            # constraint: LMI <= 0 \n",
    "            LMI = LMI_outer.T @ LMI_inner @ LMI_outer\n",
    "            LMI_system.append(LMI << 0)\n",
    "\n",
    "            # constraint: P(p) > 0\n",
    "            LMI_system.append(P_k   >> eps*I_n_eta)\n",
    "            LMI_system.append(P_kp1 >> eps*I_n_eta)\n",
    "\n",
    "            # constraint: P(p) <= t*I\n",
    "            LMI_system.append(P_k   << t_I)\n",
    "            LMI_system.append(P_kp1 << t_I)\n",
    "\n",
    "            # constraint: 1/t*I <= P(p) (Convexified via Schur complement)\n",
    "            LMI_system.append(cvx.bmat([[P_k,   I_n_eta],[I_n_eta, t_I]]) >> 0)\n",
    "            LMI_system.append(cvx.bmat([[P_kp1, I_n_eta],[I_n_eta, t_I]]) >> 0)\n",
    "\n",
    "        ### solve problem\n",
    "        problem = cvx.Problem(cvx.Minimize(t), LMI_system)\n",
    "\n",
    "        try:\n",
    "            problem.solve(solver=cvx.MOSEK)\n",
    "        except(cvx.SolverError):\n",
    "            pass\n",
    "    \n",
    "        if problem.status == cvx.OPTIMAL:\n",
    "            rho_max = rho\n",
    "            sol = (lyap.min_max_eigval(list(zip(*consistent_polytope))[0]), lambd1, lambd2, gamm, t.value)\n",
    "        else:\n",
    "            rho_min = rho\n",
    "\n",
    "        del lyap\n",
    "        \n",
    "    return rho_max, sol\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_range = np.logspace(np.log10(1/0.8 + 1e-3), 2, 10)\n",
    "\n",
    "rhos_fast, rhos_middle, rhos_slow, rho_nom = (list() for _ in range(4))\n",
    "\n",
    "n_sparse = 4\n",
    "\n",
    "### select algorithm\n",
    "algorithm = GradientDescent(nx=1)\n",
    "# algorithm = Nesterov(nx=1)\n",
    "# algorithm = TMM(nx=1)\n",
    "\n",
    "\n",
    "for kappa in tqdm(kappa_range):\n",
    "\n",
    "    ### Create consistent polytope grid over parameters\n",
    "    kappa_min, kappa_max = kappa * 0.8, kappa\n",
    "    grid_step = (kappa_max - kappa_min) / n_sparse\n",
    "\n",
    "    params = np.linspace(kappa_min, kappa_max, n_sparse + 1)\n",
    "    delta_kappa_max = lambda rate_bound: rate_bound * (kappa_max - kappa_min)\n",
    "\n",
    "    grid_points_fast = ConsistentPolytope(params, -delta_kappa_max(rate_bound=1), delta_kappa_max(rate_bound=1), step_size=grid_step)\n",
    "    grid_points_mod  = ConsistentPolytope(params, -delta_kappa_max(rate_bound=0.5), delta_kappa_max(rate_bound=0.5), step_size=grid_step)\n",
    "    grid_points_slow = ConsistentPolytope(params, -delta_kappa_max(rate_bound=0.05), delta_kappa_max(rate_bound=0.05), step_size=grid_step)\n",
    "    grid_static = [(np.array([kappa]), np.array([0]))]\n",
    "\n",
    "\n",
    "    rho, _ = bisection(algorithm=algorithm,\n",
    "                        delta_model=False,\n",
    "                        rho_max=1.5, \n",
    "                        consistent_polytope=grid_points_fast,\n",
    "                        eps=1e-6)\n",
    "    rhos_fast.append(rho)\n",
    "\n",
    "    rho, sol = bisection(algorithm=algorithm,\n",
    "                        delta_model=False,\n",
    "                        rho_max=1.5, \n",
    "                        consistent_polytope=grid_points_mod,\n",
    "                        eps=1e-6)\n",
    "    rhos_middle.append(rho)\n",
    "\n",
    "\n",
    "    rho, _ = bisection(algorithm=algorithm,\n",
    "                        delta_model=False,\n",
    "                        rho_max=1.5, \n",
    "                        consistent_polytope=grid_points_slow,\n",
    "                        eps=1e-6)\n",
    "    rhos_slow.append(rho)\n",
    "\n",
    "    rho, _ = bisection(algorithm=algorithm,\n",
    "                        delta_model=False,\n",
    "                        rho_max=1.5, \n",
    "                        consistent_polytope=grid_static,\n",
    "                        eps=1e-6)\n",
    "    rho_nom.append(rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m kappa_range, rho_nom, rhos_fast, rhos_middle, rhos_slow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(np\u001b[38;5;241m.\u001b[39marray, [kappa_range, rho_nom, rhos_fast, rhos_middle, rhos_slow])\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39msemilogx(\u001b[43mkappa_range\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrho_nom\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, rho_nom[rho_nom \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-*\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkappa fixed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msemilogx(kappa_range[rhos_fast \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m], rhos_fast[rhos_fast \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--+\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msemilogx(kappa_range[rhos_middle \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m], rhos_middle[rhos_middle \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--+\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.5vmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 4"
     ]
    }
   ],
   "source": [
    "kappa_range, rho_nom, rhos_fast, rhos_middle, rhos_slow = map(np.array, [kappa_range, rho_nom, rhos_fast, rhos_middle, rhos_slow])\n",
    "\n",
    "plt.semilogx(kappa_range[rho_nom <= 1], rho_nom[rho_nom <= 1], '-*', label='kappa fixed')\n",
    "plt.semilogx(kappa_range[rhos_fast <= 1], rhos_fast[rhos_fast <= 1], '--+', label='vmax')\n",
    "plt.semilogx(kappa_range[rhos_middle <= 1], rhos_middle[rhos_middle <= 1], '--+', label='0.5vmax')\n",
    "plt.semilogx(kappa_range[rhos_slow <= 1], rhos_slow[rhos_slow <= 1], '--*', label='0.05 vmax')\n",
    "\n",
    "plt.xlabel('kappa (L/m)')\n",
    "plt.ylabel('decay rate (rho)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
